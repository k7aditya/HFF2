[*] Load /home/manish/BrainTumorHFF/HFF/data/brats20/final/0-train.txt, which contains 295 paired volume
modilities: ['flair_L', 't1_L', 't1ce_L', 't2_L', 'flair_H1', 'flair_H2', 'flair_H3', 'flair_H4', 't1_H1', 't1_H2', 't1_H3', 't1_H4', 't1ce_H1', 't1ce_H2', 't1ce_H3', 't1ce_H4', 't2_H1', 't2_H2', 't2_H3', 't2_H4']
[*] Load /home/manish/BrainTumorHFF/HFF/data/brats20/final/0-val.txt, which contains 36 paired volume
modilities: ['flair_L', 't1_L', 't1ce_L', 't2_L', 'flair_H1', 'flair_H2', 'flair_H3', 'flair_H4', 't1_H1', 't1_H2', 't1_H3', 't1_H4', 't1ce_H1', 't1ce_H2', 't1ce_H3', 't1ce_H4', 't2_H1', 't2_H2', 't2_H3', 't2_H4']
[LOAD] Loading from: /home/manish/BrainTumorHFF/HFF/result/checkpoints/hff/brats20/all/hff-l=0.3-e=200-s=50-g=0.55-b=1-cw=15-w=3-100L-H-2025-11-14_11-06-41/best_Result1_et_0.7482_tc_0.7259_wt_0.7908.pth
[LOAD] âœ“ Checkpoint loaded successfully
Set dropout rate to 0.5000 (18 layers)
Set dropout rate to 0.2000 (18 layers)
Traceback (most recent call last):
  File "/home/manish/BrainTumorHFF/HFF/train_multiGPU_fix.py", line 471, in <module>
    outputs_train_1, outputs_train_2,side1,side2 = model(low_freq_inputs, high_freq_inputs)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/manish/BrainTumorHFF/HFF/model/HFF_MobileNetV3_fixed.py", line 438, in forward
    layer1_LF, layer2_LF, layer3_LF, layer4_LF_1, layer5_LF_1 = self.mobilenet_encoder_b1(input1)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/manish/BrainTumorHFF/HFF/model/HFF_MobileNetV3_fixed.py", line 103, in forward
    x = self.stem(x)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/manish/BrainTumorHFF/HFF/model/HFF_MobileNetV3_fixed.py", line 26, in forward
    return x * F.relu6(x + 3., inplace=self.inplace) / 6.
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 1; 23.70 GiB total capacity; 1.00 GiB already allocated; 49.56 MiB free; 1.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
