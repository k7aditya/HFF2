[34m[1mwandb[0m: Currently logged in as: [33mk7aditya[0m ([33mk7aditya-iiita-alumni-affairs[0m) to [32mhttps://api.wandb.ai[0m. Use [1m`wandb login --relogin`[0m to force relogin
[34m[1mwandb[0m: setting up run 9enpxd4v (0.0s)
[Am[2K[34m[1mwandb[0m: setting up run 9enpxd4v (0.0s)
[Am[2K[34m[1mwandb[0m: setting up run 9enpxd4v (0.0s)
[Am[2K[34m[1mwandb[0m: setting up run 9enpxd4v (0.0s)
[Am[2K[34m[1mwandb[0m: setting up run 9enpxd4v (0.0s)
[Am[2K[34m[1mwandb[0m: Tracking run with wandb version 0.22.3
[34m[1mwandb[0m: Run data is saved locally in [35m[1m/home/manish/BrainTumorHFF/HFF/wandb/run-20251114_013833-9enpxd4v[0m
[34m[1mwandb[0m: Run [1m`wandb offline`[0m to turn off syncing.
[34m[1mwandb[0m: Syncing run [33mlyric-lake-22[0m
[34m[1mwandb[0m:  View project at [34m[4mhttps://wandb.ai/k7aditya-iiita-alumni-affairs/learning%20rate%3D0.3epochs%3D200-step_size%3D50-gamma%3D0.55weight%20between%20braches%3D15warmup%20epochs%3D3brats20_all[0m
[34m[1mwandb[0m:  View run at [34m[4mhttps://wandb.ai/k7aditya-iiita-alumni-affairs/learning%20rate%3D0.3epochs%3D200-step_size%3D50-gamma%3D0.55weight%20between%20braches%3D15warmup%20epochs%3D3brats20_all/runs/9enpxd4v[0m
[*] Load /home/manish/BrainTumorHFF/HFF/data/brats20/final/0-train.txt, which contains 295 paired volume
modilities: ['flair_L', 't1_L', 't1ce_L', 't2_L', 'flair_H1', 'flair_H2', 'flair_H3', 'flair_H4', 't1_H1', 't1_H2', 't1_H3', 't1_H4', 't1ce_H1', 't1ce_H2', 't1ce_H3', 't1ce_H4', 't2_H1', 't2_H2', 't2_H3', 't2_H4']
[*] Load /home/manish/BrainTumorHFF/HFF/data/brats20/final/0-val.txt, which contains 36 paired volume
modilities: ['flair_L', 't1_L', 't1ce_L', 't2_L', 'flair_H1', 'flair_H2', 'flair_H3', 'flair_H4', 't1_H1', 't1_H2', 't1_H3', 't1_H4', 't1ce_H1', 't1ce_H2', 't1ce_H3', 't1ce_H4', 't2_H1', 't2_H2', 't2_H3', 't2_H4']
Set dropout rate to 0.5000 (18 layers)
Set dropout rate to 0.3780 (18 layers)
Epoch 62 - Dropout rate set to 0.3780
  0%|                                                                          | 0/295 [00:00<?, ?it/s]  0%|2                                                                 | 1/295 [00:09<45:15,  9.24s/it]  1%|4                                                                 | 2/295 [00:10<22:30,  4.61s/it]  1%|6                                                                 | 3/295 [00:11<15:02,  3.09s/it]  1%|8                                                                 | 4/295 [00:13<11:27,  2.36s/it]  2%|#1                                                                | 5/295 [00:14<09:36,  1.99s/it]  2%|#3                                                                | 6/295 [00:15<08:34,  1.78s/it]  2%|#5                                                                | 7/295 [00:17<07:44,  1.61s/it]  3%|#7                                                                | 8/295 [00:18<07:15,  1.52s/it]  3%|##                                                                | 9/295 [00:19<06:52,  1.44s/it]  3%|##2                                                              | 10/295 [00:20<06:39,  1.40s/it]  4%|##4                                                              | 11/295 [00:22<06:37,  1.40s/it]  4%|##6                                                              | 12/295 [00:23<06:31,  1.38s/it]  4%|##8                                                              | 13/295 [00:24<06:19,  1.35s/it]  5%|###                                                              | 14/295 [00:26<06:23,  1.36s/it]  5%|###3                                                             | 15/295 [00:27<06:14,  1.34s/it]  5%|###5                                                             | 16/295 [00:28<06:10,  1.33s/it]  6%|###7                                                             | 17/295 [00:30<06:05,  1.32s/it]  6%|###9                                                             | 18/295 [00:31<06:06,  1.32s/it]  6%|####1                                                            | 19/295 [00:32<06:03,  1.32s/it]  7%|####4                                                            | 20/295 [00:34<05:58,  1.30s/it]  7%|####6                                                            | 21/295 [00:35<06:12,  1.36s/it]  7%|####8                                                            | 22/295 [00:36<06:04,  1.34s/it]  8%|#####                                                            | 23/295 [00:38<06:02,  1.33s/it]  8%|#####2                                                           | 24/295 [00:39<06:00,  1.33s/it]  8%|#####5                                                           | 25/295 [00:40<05:54,  1.31s/it]  9%|#####7                                                           | 26/295 [00:42<05:55,  1.32s/it]  9%|#####9                                                           | 27/295 [00:43<05:53,  1.32s/it]  9%|######1                                                          | 28/295 [00:44<05:58,  1.34s/it]  9%|######1                                                          | 28/295 [00:45<07:18,  1.64s/it]
Traceback (most recent call last):
  File "/home/manish/BrainTumorHFF/HFF/train_new.py", line 449, in <module>
    loss_train.backward()
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/manish/.conda/envs/hff-xai/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
